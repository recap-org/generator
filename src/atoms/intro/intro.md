Reproducibility is now widely recognized as a central concern in empirical research. Recent work by @lambda2024defaults emphasizes that many irreproducible results stem not from flawed methods, but from undocumented defaults, missing metadata, and fragile workflows. Here, we argue that even _entirely plausible_ results may _fail to reproduce_ when computational environments are not explicitly specified.

This paper follows that perspective. Using a simple dataset on student outcomes [@student_exam_scores_kaggle], we estimate a conventional regression model and present the results in tabular and graphical form (Section @sec-results). The goal is not to uncover new empirical insights, but to provide a compact, transparent example that can be reproduced end-to-end with minimal effort.